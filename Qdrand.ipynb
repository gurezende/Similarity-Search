{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client.models import Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model to generate embeddings for the text in the dataframe\n",
    "model = SentenceTransformer(\n",
    "    model_name_or_path=\"all-MiniLM-L12-v2\", device=\"cpu\",\n",
    "    similarity_fn_name=\"cosine\"\n",
    ")  # device=\"cpu\" or device=\"cuda\" for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data Startup Demo Dataset\n",
    "# df = pd.read_json(\"https://storage.googleapis.com/generall-shared-data/startups_demo.json\", lines=True)\n",
    "# df = df.sample(2000)\n",
    "# df.to_json(\"stt.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News</th>\n",
       "      <th>published_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Jonathan Nuñez had a liver transplant in which...</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>Cancer Risk Doubles After  Organ Transplant, S...</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>Well: Life, Interrupted: A Golden Opportunity ...</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   News  published_year\n",
       "66    Jonathan Nuñez had a liver transplant in which...            2014\n",
       "1430  Cancer Risk Doubles After  Organ Transplant, S...            2011\n",
       "1014  Well: Life, Interrupted: A Golden Opportunity ...            2013"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data Health News\n",
    "df = pd.read_json(\"healthnews.json\", lines=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df[\"published_year\"] = df[\"Date\"].dt.year\n",
    "df.drop(columns=[\"Date\"], inplace=True)\n",
    "df.to_json(\"healthnews_yr.json\", orient=\"records\", lines=True)\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 63/63 [00:13<00:00,  4.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode the text: embeddings\n",
    "vectors = model.encode(\n",
    "    df[\"News\"].tolist(),\n",
    "    show_progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 63/63 [00:25<00:00,  2.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# Startups dataset: Encode the text: embeddings\n",
    "# vectors = model.encode(\n",
    "#     [row.alt + \". \" + row.description for row in df.itertuples()],\n",
    "#     show_progress_bar=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the descriptions are now converted into vectors. There are 2000 vectors of 384 dimensions. The output layer of the model has this dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe: Well: Savory and Sweet Whole Wheat Focaccia http://nyti.ms/1oXFmKS\n",
      "---\n",
      "Vector: [ 0.081046   -0.01129879  0.05162172  0.03999408  0.02012923  0.00079972\n",
      " -0.02407607  0.05108334 -0.04262673 -0.02786539 -0.02297052 -0.02726727\n",
      " -0.00324672  0.05730832 -0.05912046 -0.02010428  0.0059504  -0.04927275\n",
      " -0.05108761  0.0612146   0.04456822  0.00351208  0.08726088  0.00944512\n",
      "  0.01153558 -0.1233921   0.00166522 -0.04746857 -0.0656888   0.00487615]\n",
      "---\n",
      "(2000, 384)\n"
     ]
    }
   ],
   "source": [
    "# View first row of the dataframe\n",
    "print('Dataframe:', df[\"News\"][1])\n",
    "print('---')\n",
    "print('Vector:', vectors[0][0:30])\n",
    "print('---')\n",
    "print(vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the vectors\n",
    "np.save(\"healthnews_vectors.npy\", vectors, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 modes of use:\n",
    "* Memory mode\n",
    "* Local host\n",
    "* Cloud host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCAL HOST MODE: Open Qdrant client\n",
    "# qdrant_client = QdrantClient(\"http://localhost:6333\")\n",
    "\n",
    "# MEMORY MAPPED MODE: Open Qdrant client\n",
    "qdrant_client = QdrantClient(\":memory:\")\n",
    "\n",
    "# from qdrant_client import QdrantClient\n",
    "\n",
    "# qdrant_client = QdrantClient(\n",
    "#     url=\"https://xxxxxx-xxxxx-xxxxx-xxxx-xxxxxxxxx.us-east.aws.cloud.qdrant.io:6333\",\n",
    "#     api_key=\"<your-api-key>\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a collection\n",
    "if not qdrant_client.collection_exists(\"health_news\"):\n",
    "    qdrant_client.create_collection(\n",
    "        collection_name=\"health_news\",\n",
    "        vectors_config=VectorParams(size=384, distance=Distance.COSINE),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdrant_client.collection_exists(\"health_news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are two ways to know the embedding dimension of the model\n",
    "model.get_sentence_embedding_dimension()\n",
    "\n",
    "# or\n",
    "\n",
    "vectors.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = open(\"healthnews_yr.json\")\n",
    "\n",
    "# payload is now an iterator over startup data\n",
    "payload = map(json.loads, fd)\n",
    "\n",
    "# Load all vectors into memory, numpy array works as iterable for itself.\n",
    "# Other option would be to use Mmap, if you don't want to load all data into RAM\n",
    "vectors = np.load(\"healthnews_vectors.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload data to Qdrant\n",
    "qdrant_client.upload_collection(\n",
    "    collection_name=\"health_news\",\n",
    "    vectors=vectors,\n",
    "    payload=payload,\n",
    "    ids=None,  # Vector ids will be assigned automatically\n",
    "    batch_size=384,  # How many vectors will be uploaded in a single request?\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionInfo(status=<CollectionStatus.GREEN: 'green'>, optimizer_status=<OptimizersStatusOneOf.OK: 'ok'>, vectors_count=None, indexed_vectors_count=0, points_count=2000, segments_count=1, config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=384, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None, datatype=None, multivector_config=None), shard_number=None, sharding_method=None, replication_factor=None, write_consistency_factor=None, read_fan_out_factor=None, on_disk_payload=None, sparse_vectors=None), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=None, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=None, indexing_threshold=20000, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=None, strict_mode_config=None), payload_schema={})"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdrant_client.get_collection(\"health_news\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to process incoming requests, neural search will need 2 things: 1) a model to convert the query into a vector and 2) the Qdrant client to perform search queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralSearcher:\n",
    "    def __init__(self, collection_name):\n",
    "        self.collection_name = collection_name\n",
    "        # Initialize encoder model\n",
    "        self.model = SentenceTransformer(\"all-MiniLM-L12-v2\", device=\"cpu\", similarity_fn_name=\"cosine\")\n",
    "        # initialize Qdrant client\n",
    "        self.qdrant_client = qdrant_client\n",
    "\n",
    "\n",
    "    def search(self, text: str):\n",
    "        # Convert text query into vector\n",
    "        vector = self.model.encode(text).tolist()\n",
    "    \n",
    "        # Use `vector` for search for closest vectors in the collection\n",
    "        search_result = self.qdrant_client.query_points(\n",
    "            collection_name=self.collection_name,\n",
    "            query=vector,\n",
    "            query_filter=None,  # If you don't want any filters for now\n",
    "            limit=3,  # 3 the most closest results is enough\n",
    "        ).points\n",
    "        # `search_result` contains found vector ids with similarity scores along with the stored payload\n",
    "        # Hit payload and scores\n",
    "        payloads = [(hit.payload['News'], hit.score) for hit in search_result]\n",
    "        return payloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Qdrant it is also feasible to add some conditions to the search. For example, if you wanted to search for startups in a certain city, the search query could look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching with Filter\n",
    "\n",
    "class NeuralSearcher:\n",
    "    def __init__(self, collection_name, qdrant_client):\n",
    "        self.collection_name = collection_name\n",
    "        # Initialize encoder model\n",
    "        self.model = SentenceTransformer(\"all-MiniLM-L12-v2\", device=\"cpu\")\n",
    "        # initialize Qdrant client\n",
    "        self.qdrant_client = qdrant_client\n",
    "\n",
    "\n",
    "    def search(self, text: str, published_year: int):\n",
    "        # Convert text query into vector\n",
    "        vector = self.model.encode(text).tolist()\n",
    "\n",
    "        published_year = published_year\n",
    "        # Define a filter for cities\n",
    "        year_filter = Filter(**{\n",
    "            \"must\": [{\n",
    "                \"key\": \"published_year\", # Store the information in a field of the same name \n",
    "                \"match\": { # This condition checks if payload field has the requested value\n",
    "                    \"value\": published_year }\n",
    "            }]\n",
    "        })\n",
    "        \n",
    "        search_result = self.qdrant_client.query_points(\n",
    "            collection_name=self.collection_name,\n",
    "            query=vector,\n",
    "            query_filter=year_filter,\n",
    "            limit=3\n",
    "        ).points\n",
    "        \n",
    "        # `search_result` contains found vector ids with similarity scores along with the stored payload\n",
    "        # In this function you are interested in payload only\n",
    "        payloads = [f\"> Score: {round(hit.score,4)}, |> Text: {hit.payload['News']}, |> Year: { hit.payload['published_year']})\" for hit in search_result]\n",
    "\n",
    "        return payloads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 516 ms\n",
      "Wall time: 850 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['> Score: 0.6032, |> Text: Well: The Advanced 7-Minute Workout http://nyti.ms/10rsibq, |> Year: 2014)',\n",
       " '> Score: 0.5792, |> Text: Download the 7-Minute Workout app from atnytimeswell for iPhone and Android http://nyti.ms/ZQrfkz http://pbs.twimg.com/media/B0vj0v0CQAAl0dp.jpg, |> Year: 2014)',\n",
       " '> Score: 0.48, |> Text: Instead of a large all-out workout, have you tried exercising in snack-size portions?  http://nyti.ms/1jtdqKX, |> Year: 2014)']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Instantiate NeuralSearcher\n",
    "searcher = NeuralSearcher(collection_name=\"health_news\",\n",
    "                           qdrant_client=qdrant_client)\n",
    "\n",
    "# Query\n",
    "q = \"Quick Workout\"\n",
    "searcher.search(text=q,\n",
    "                published_year=2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
